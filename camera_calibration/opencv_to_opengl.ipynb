{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Converting Camera Matrix (openCV) to openGl\n",
    "#   Sources:\n",
    "#   http://www.info.hiroshima-cu.ac.jp/~miyazaki/knowledge/teche0092.html\n",
    "#   https://fruty.io/2019/08/29/augmented-reality-with-opencv-and-opengl-the-tricky-projection-matrix/\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "np.set_printoptions(suppress=True,\n",
    "                    formatter={'float_kind': '{:f},'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_projections(point, camera_mtx, opengl_mtx):\n",
    "    print(point)\n",
    "    #     \n",
    "    # screen_point, _ = cv2.projectPoints(np.array([point]), np.zeros(3), np.zeros(3), camera_mtx, np.zeros(5))\n",
    "    # print(screen_point)\n",
    "\n",
    "    #Note: we obtain the same result with this: (that's what cv2.projectPoints basically does: multiply points with camera matrix and then divide result by z coord)\n",
    "    open_cv = camera_mtx.dot(point)/point[2]\n",
    "    print(open_cv)\n",
    "\n",
    "\n",
    "    #### OpenGL projection\n",
    "    #we flip the point z coord, because in opengl camera is oriented along -Oz axis\n",
    "    point[2] = -point[2]\n",
    "    point2 = np.hstack([point,1.0]) #we add vertex w coord (usually done in vertex shader before multiplying by projection matrix)\n",
    "    #we get the point in clip space\n",
    "\n",
    "    clip_point = opengl_mtx.dot(point2)\n",
    "\n",
    "    #NOTE: what follows \"simulates\" what happens in OpenGL after the vertex shader.\n",
    "    #This is necessary so that we can make sure our projection matrix will yield the correct result when used in OpenGL\n",
    "    #we get the point in NDC\n",
    "\n",
    "    ndc_point = clip_point / clip_point[3]\n",
    "    #we get the screen coordinates\n",
    "    viewport_point = (ndc_point + 1.0)/2.0 * np.array([w, h, 1.0, 1.0])\n",
    "    #opencv Oy convention is opposite of OpenGL so we reverse y coord\n",
    "    viewport_point[1] = h - viewport_point[1]\n",
    "    \n",
    "    print(viewport_point)\n",
    "    print()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV Matrix\n",
      "[[954.402456, 0.000000, 356.109935,]\n",
      " [0.000000, 951.810046, 644.814334,]\n",
      " [0.000000, 0.000000, 1.000000,]] \n",
      "\n",
      "OpenGL Matrix\n",
      "[[2.651118, 0.000000, 0.010806, 0.000000,]\n",
      " [0.000000, -1.487203, -0.007522, 0.000000,]\n",
      " [0.000000, 0.000000, -1.105263, -2.105263,]\n",
      " [0.000000, 0.000000, -1.000000, 0.000000,]] \n",
      "\n",
      "Image Properties\n",
      "width :  720.0\n",
      "height:  1280.0 \n",
      "\n",
      "[-1.000000, -1.000000, 10.000000,]\n",
      "[260.669690, 549.633330, 1.000000,]\n",
      "[260.669690, 540.004661, 0.947368, 1.000000,]\n",
      "\n",
      "[1.000000, -1.000000, 10.000000,]\n",
      "[451.550181, 549.633330, 1.000000,]\n",
      "[451.550181, 540.004661, 0.947368, 1.000000,]\n",
      "\n",
      "[1.000000, 1.000000, 10.000000,]\n",
      "[451.550181, 739.995339, 1.000000,]\n",
      "[451.550181, 730.366670, 0.947368, 1.000000,]\n",
      "\n",
      "[-1.000000, 1.000000, 10.000000,]\n",
      "[260.669690, 739.995339, 1.000000,]\n",
      "[260.669690, 730.366670, 0.947368, 1.000000,]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Camera Matrix (OpenCV)\n",
    "camera_mtx = np.loadtxt(fname='camera_matrix.txt', delimiter=',')\n",
    "info =  np.loadtxt(fname='image_info.txt', delimiter=',')\n",
    "\n",
    "cx = camera_mtx[0][2]\n",
    "cy = camera_mtx[1][2]\n",
    "\n",
    "fx = camera_mtx[0][0]\n",
    "fy = camera_mtx[1][1]\n",
    "\n",
    "w = info[0]\n",
    "h = info[1]\n",
    "\n",
    "near = 1\n",
    "far = 20\n",
    "\n",
    "opengl_mtx = np.array([\n",
    "    [2*fx/w, 0.0, (w - 2*cx)/w, 0.0],\n",
    "    [0.0, -2*fy/h, (h - 2*cy)/h, 0.0],\n",
    "    [0.0, 0.0, (-far - near) / (far - near), -2.0*far*near/(far-near)],\n",
    "    [0.0, 0.0, -1.0, 0.0]\n",
    "])\n",
    "\n",
    "np.savetxt(fname='opengl_matrix.txt',X=opengl_mtx, delimiter=',',header='opengl_mtx')\n",
    "\n",
    "\n",
    "output_file = open('opengl_output.txt', 'w')\n",
    "output_file.write(str(opengl_mtx) + '\\n\\n')\n",
    "\n",
    "print('OpenCV Matrix')\n",
    "print(camera_mtx, '\\n')\n",
    "print('OpenGL Matrix')\n",
    "print(opengl_mtx, '\\n')\n",
    "print('Image Properties')\n",
    "print('width : ',w)\n",
    "print('height: ',h,'\\n')\n",
    "\n",
    "points = [\n",
    "    # np.array([0.0, 0.0, 1.0]),\n",
    "    # np.array([20.0, 40.0, 100.0]),\n",
    "    # np.array([300.0, 600.0, 1000.0])\n",
    "    np.array([-1.0, -1.0, 10.0]),\n",
    "    np.array([1.0, -1.0, 10.0]),\n",
    "    np.array([1.0, 1.0, 10.0]),\n",
    "    np.array([-1.0, 1.0, 10.0]),\n",
    "]\n",
    "\n",
    "for point in points:\n",
    "   compare_projections(point=point,camera_mtx=camera_mtx,opengl_mtx=opengl_mtx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_opencv(points, camera_mtx):\n",
    "    projection = []\n",
    "\n",
    "    for point in points:\n",
    "        open_cv = camera_mtx.dot(point)/point[2]\n",
    "        projection.append([open_cv[0], open_cv[1]])\n",
    "\n",
    "    return projection\n",
    "   \n",
    "def project_opengl(points, opengl_mtx):\n",
    "    projection = []\n",
    "\n",
    "    for point in points:\n",
    "        #### OpenGL projection\n",
    "        #we flip the point z coord, because in opengl camera is oriented along -Oz axis\n",
    "        point[2] = -point[2]\n",
    "        point2 = np.hstack([point,1.0]) #we add vertex w coord (usually done in vertex shader before multiplying by projection matrix)\n",
    "        #we get the point in clip space\n",
    "        clip_point = opengl_mtx.dot(point2)\n",
    "\n",
    "        print(clip_point)\n",
    "\n",
    "        #NOTE: what follows \"simulates\" what happens in OpenGL after the vertex shader.\n",
    "        #This is necessary so that we can make sure our projection matrix will yield the correct result when used in OpenGL\n",
    "        #we get the point in NDC\n",
    "\n",
    "        ndc_point = clip_point / clip_point[3]\n",
    "        #we get the screen coordinates\n",
    "        viewport_point = (ndc_point + 1.0)/2.0 * np.array([w, h, 1.0, 1.0])\n",
    "        #opencv Oy convention is opposite of OpenGL so we reverse y coord\n",
    "        viewport_point[1] = h - viewport_point[1]\n",
    "        \n",
    "        # print(viewport_point)\n",
    "        projection.append([viewport_point[0], viewport_point[1]])\n",
    "        \n",
    "    return projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.519418, -0.289918, -1.000000, 1.000000,]\n",
      "[0.784530, -0.289918, -1.000000, 1.000000,]\n",
      "[0.784530, -0.438639, -1.000000, 1.000000,]\n",
      "[0.519418, -0.438639, -1.000000, 1.000000,]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "points = [\n",
    "    # np.array([-0.1, -0.1, 10.0]),\n",
    "    # np.array([0.1, -0.1, 10.0]),\n",
    "    # np.array([0.1, 0.1, 10.0]),\n",
    "    # np.array([-0.1, 0.1, 10.0]),\n",
    "    np.array([0.2, 0.2, 1.0]),\n",
    "    np.array([0.3, 0.2, 1.0]),\n",
    "    np.array([0.3, 0.3, 1.0]),\n",
    "    np.array([0.2, 0.3, 1.0]),\n",
    "]\n",
    "\n",
    "open_cv_projection = project_opencv(points, camera_mtx)\n",
    "open_gl_projection = project_opengl(points, opengl_mtx)\n",
    "\n",
    "# print(open_cv_projection[0])\n",
    "# print(open_cv_projection[1])\n",
    "# print(open_cv_projection[2])\n",
    "# print(open_cv_projection[3])\n",
    "# print()\n",
    "# print(open_gl_projection[0])\n",
    "# print(open_gl_projection[1])\n",
    "# print(open_gl_projection[2])\n",
    "# print(open_gl_projection[3])\n",
    "\n",
    "#Draw Shape \n",
    "\n",
    "\n",
    "coord = open_cv_projection\n",
    "coord.append(open_cv_projection[0]) #repeat the first point to create a 'closed loop'\n",
    "\n",
    "coord1 = open_gl_projection\n",
    "coord1.append(open_gl_projection[0])\n",
    "\n",
    "xs, ys = zip(*open_cv_projection) #create lists of x and y values\n",
    "xs1,ys1 = zip(*open_gl_projection)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(xs,ys) \n",
    "plt.plot(xs1,ys1) \n",
    "\n",
    "plt.show() # if you need..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0fb525d995e0958798e36914dbbeebf9776adb9826b1870f56d9f091777d3cbd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
